{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Model optimization\n",
    "\n",
    "\n",
    "Gruppe Nummer: 1\n",
    "- Samuel Hempelt\n",
    "- Andreas Luakat\n",
    "- John Torres\n",
    "\n",
    "In this step we will use the data create after applying the preprocessed steps on Step 3, since this generated the best model from all other preprocessed steps: \n",
    "\n",
    "- Step 3: Outlier Cleaning\n",
    "    - Missing Values: Average for numeric, Mode for Category\n",
    "    - Deletion of entries with missing values in the target colunm\n",
    "    - Listwise deletion (all rows with multiple missing values, more than 2)\n",
    "    - Identify outlier with IQR\n",
    "    - Impute outliers with regression imputation\n",
    "    - Impute categorical values with random imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(train_x: pd.DataFrame, \n",
    "                        val_x: pd.DataFrame, \n",
    "                        train_y: pd.DataFrame, \n",
    "                        val_y: pd.DataFrame,\n",
    "                        random_seed: int = 123,\n",
    "                        n_opt_trials = 20,\n",
    "                        cv: int = 5) -> tuple:\n",
    "\n",
    "    # Train model without optimization\n",
    "    model_no_opt = RandomForestClassifier(random_state=random_seed)\n",
    "    model_no_opt.fit(train_x, train_y)\n",
    "    y_pred = model_no_opt.predict(val_x)\n",
    "    f1_no_opt = f1_score(val_y, y_pred)\n",
    "\n",
    "    print(f\"F1 Score No Optimization: {f1_no_opt}\")\n",
    "    \n",
    "    def objective(trial):\n",
    "\n",
    "        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32, log=True)\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 10, 100)\n",
    "        classifier_obj = RandomForestClassifier(\n",
    "            max_depth=rf_max_depth, \n",
    "            n_estimators=n_estimators,\n",
    "            random_state=random_seed\n",
    "        )\n",
    "\n",
    "        score = cross_val_score(classifier_obj, train_x, train_y, n_jobs=-1, cv=cv, scoring=\"f1_weighted\")\n",
    "        return score.mean()\n",
    "    \n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_opt_trials)\n",
    "\n",
    "    # train model with optimized hyperparameters\n",
    "    model = RandomForestClassifier(max_depth=study.best_params[\"rf_max_depth\"], \n",
    "                                    n_estimators=study.best_params[\"n_estimators\"], \n",
    "                                    random_state=random_seed)\n",
    "\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    # prediction\n",
    "    y_pred = model.predict(val_x)\n",
    "    val_f1_score = round(f1_score(val_y, y_pred),4)\n",
    "    val_accuracy = round(accuracy_score(val_y, y_pred),4)\n",
    "    \n",
    "    print(\"Optimized Model F1 Score: \", val_f1_score)\n",
    "    \n",
    "    # check if no optimization has better f1 score\n",
    "    if f1_no_opt > val_f1_score:\n",
    "        print(\"No Optimization has better f1 score than optimized model\")\n",
    "        model = model_no_opt\n",
    "        val_f1_score = f1_no_opt\n",
    "    \n",
    "    return model, study, val_f1_score, val_accuracy\n",
    "\n",
    "def train_gradient_boosting(train_x: pd.DataFrame, \n",
    "                        val_x: pd.DataFrame, \n",
    "                        train_y: pd.DataFrame, \n",
    "                        val_y: pd.DataFrame,\n",
    "                        random_seed: int = 123,\n",
    "                        n_opt_trials = 20,\n",
    "                        cv: int = 5) -> tuple:\n",
    "\n",
    "    # Train model without optimization\n",
    "    model_no_opt = GradientBoostingClassifier(random_state=random_seed)\n",
    "    model_no_opt.fit(train_x, train_y)\n",
    "    y_pred = model_no_opt.predict(val_x)\n",
    "    f1_no_opt = f1_score(val_y, y_pred)\n",
    "\n",
    "    print(f\"F1 Score No Optimization: {f1_no_opt}\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        rf_max_depth = trial.suggest_int(\"max_depth\", 2, 32, log=True)\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 10, 100)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 1.0, log=True)\n",
    "        classifier_obj = GradientBoostingClassifier(\n",
    "            max_depth=rf_max_depth, \n",
    "            n_estimators=n_estimators, \n",
    "            learning_rate=learning_rate,\n",
    "            random_state=random_seed\n",
    "        )\n",
    "\n",
    "        score = cross_val_score(classifier_obj, train_x, train_y, n_jobs=-1, cv=cv, scoring=\"f1_weighted\")\n",
    "        return score.mean()\n",
    "    \n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_opt_trials)\n",
    "\n",
    "    # train model with optimized hyperparameters\n",
    "    model = GradientBoostingClassifier(max_depth=study.best_params[\"max_depth\"], \n",
    "                                    n_estimators=study.best_params[\"n_estimators\"], \n",
    "                                    random_state=random_seed,)\n",
    "\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    # prediction\n",
    "    y_pred = model.predict(val_x)\n",
    "    val_f1_score = round(f1_score(val_y, y_pred),4)\n",
    "    val_accuracy = round(accuracy_score(val_y, y_pred),4)\n",
    "    \n",
    "    print(\"Optimized Model F1 Score: \", val_f1_score)\n",
    "    \n",
    "    # check if no optimization has better f1 score\n",
    "    if f1_no_opt > val_f1_score:\n",
    "        print(\"No Optimization has better f1 score than optimized model\")\n",
    "        model = model_no_opt\n",
    "        val_f1_score = f1_no_opt\n",
    "    \n",
    "    return model, study, val_f1_score, val_accuracy\n",
    "\n",
    "\n",
    "def train_deicision_tree(train_x: pd.DataFrame, \n",
    "                        val_x: pd.DataFrame, \n",
    "                        train_y: pd.DataFrame, \n",
    "                        val_y: pd.DataFrame,\n",
    "                        random_seed: int = 123,\n",
    "                        n_opt_trials = 20,\n",
    "                        cv: int = 5) -> tuple:\n",
    "\n",
    "    # Train model without optimization\n",
    "    model_no_opt = DecisionTreeClassifier(random_state=random_seed)\n",
    "    model_no_opt.fit(train_x, train_y)\n",
    "    y_pred = model_no_opt.predict(val_x)\n",
    "    f1_no_opt = f1_score(val_y, y_pred)\n",
    "\n",
    "    print(f\"F1 Score No Optimization: {f1_no_opt}\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 32, log=True)\n",
    "        classifier_obj = DecisionTreeClassifier(\n",
    "            max_depth=max_depth\n",
    "        )\n",
    "\n",
    "        score = cross_val_score(classifier_obj, train_x, train_y, n_jobs=-1, cv=cv, scoring=\"f1_weighted\")\n",
    "        return score.mean()\n",
    "    \n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_opt_trials)\n",
    "\n",
    "    # train model with optimized hyperparameters\n",
    "    model = DecisionTreeClassifier(max_depth=study.best_params[\"max_depth\"],\n",
    "                                    random_state=random_seed)\n",
    "\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    # prediction\n",
    "    y_pred = model.predict(val_x)\n",
    "    val_f1_score = round(f1_score(val_y, y_pred),4)\n",
    "    val_accuracy = round(accuracy_score(val_y, y_pred),4)\n",
    "    \n",
    "    print(\"Optimized Model F1 Score: \", val_f1_score)\n",
    "    \n",
    "    # check if no optimization has better f1 score\n",
    "    if f1_no_opt > val_f1_score:\n",
    "        print(\"No Optimization has better f1 score than optimized model\")\n",
    "        model = model_no_opt\n",
    "        val_f1_score = f1_no_opt\n",
    "    \n",
    "    return model, study, val_f1_score, val_accuracy\n",
    "\n",
    "def train_adaboost(train_x: pd.DataFrame, \n",
    "                        val_x: pd.DataFrame, \n",
    "                        train_y: pd.DataFrame, \n",
    "                        val_y: pd.DataFrame,\n",
    "                        random_seed: int = 123,\n",
    "                        n_opt_trials = 20,\n",
    "                        cv: int = 5) -> tuple:\n",
    "\n",
    "    # Train model without optimization\n",
    "    model_no_opt = AdaBoostClassifier(random_state=random_seed)\n",
    "    model_no_opt.fit(train_x, train_y)\n",
    "    y_pred = model_no_opt.predict(val_x)\n",
    "    f1_no_opt = f1_score(val_y, y_pred)\n",
    "\n",
    "    print(f\"F1 Score No Optimization: {f1_no_opt}\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 10, 100)\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 1.0, log=True)\n",
    "        classifier_obj = AdaBoostClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            random_state=random_seed    \n",
    "        )\n",
    "\n",
    "        score = cross_val_score(classifier_obj, train_x, train_y, n_jobs=-1, cv=cv, scoring=\"f1_weighted\")\n",
    "        return score.mean()\n",
    "    \n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_opt_trials)\n",
    "\n",
    "    # train model with optimized hyperparameters\n",
    "    model = AdaBoostClassifier(n_estimators=study.best_params[\"n_estimators\"], \n",
    "                               learning_rate=study.best_params[\"learning_rate\"],\n",
    "                               random_state=random_seed  )\n",
    "\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    # prediction\n",
    "    y_pred = model.predict(val_x)\n",
    "    val_f1_score = round(f1_score(val_y, y_pred),4)\n",
    "    val_accuracy = round(accuracy_score(val_y, y_pred),4)\n",
    "    \n",
    "    print(\"Optimized Model F1 Score: \", val_f1_score)\n",
    "    \n",
    "    # check if no optimization has better f1 score\n",
    "    if f1_no_opt > val_f1_score:\n",
    "        print(\"No Optimization has better f1 score than optimized model\")\n",
    "        model = model_no_opt\n",
    "        val_f1_score = f1_no_opt\n",
    "    \n",
    "    return model, study, val_f1_score, val_accuracy\n",
    "\n",
    "def train_svc(train_x: pd.DataFrame, \n",
    "                        val_x: pd.DataFrame, \n",
    "                        train_y: pd.DataFrame, \n",
    "                        val_y: pd.DataFrame,\n",
    "                        random_seed: int = 123,\n",
    "                        n_opt_trials = 20,\n",
    "                        cv: int = 5) -> tuple:\n",
    "\n",
    "    # Train model without optimization\n",
    "    model_no_opt = SVC(random_state=random_seed)\n",
    "    model_no_opt.fit(train_x, train_y)\n",
    "    y_pred = model_no_opt.predict(val_x)\n",
    "    f1_no_opt = f1_score(val_y, y_pred)\n",
    "\n",
    "    print(f\"F1 Score No Optimization: {f1_no_opt}\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        #C = trial.suggest_float(\"C\", 0.1, 10, log=True)\n",
    "        kernel = trial.suggest_categorical(\"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"])\n",
    "        classifier_obj = SVC(\n",
    "            #C=C,\n",
    "            kernel=kernel,\n",
    "            random_state=random_seed    \n",
    "        )\n",
    "\n",
    "        score = cross_val_score(classifier_obj, train_x, train_y, n_jobs=-1, cv=cv, scoring=\"f1_weighted\")\n",
    "        return score.mean()\n",
    "    \n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=n_opt_trials)\n",
    "\n",
    "    # train model with optimized hyperparameters\n",
    "    model = SVC(kernel=study.best_params[\"kernel\"],\n",
    "                               random_state=random_seed  )\n",
    "\n",
    "    model.fit(train_x, train_y)\n",
    "\n",
    "    # prediction\n",
    "    y_pred = model.predict(val_x)\n",
    "    val_f1_score = round(f1_score(val_y, y_pred),4)\n",
    "    val_accuracy = round(accuracy_score(val_y, y_pred),4)\n",
    "    \n",
    "    print(\"Optimized Model F1 Score: \", val_f1_score)\n",
    "    \n",
    "    # check if no optimization has better f1 score\n",
    "    if f1_no_opt > val_f1_score:\n",
    "        print(\"No Optimization has better f1 score than optimized model\")\n",
    "        model = model_no_opt\n",
    "        val_f1_score = f1_no_opt\n",
    "    \n",
    "    return model, study, val_f1_score, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_data(df_train: pd.DataFrame,\n",
    "                df_test: pd.DataFrame,) -> tuple:\n",
    "    \"\"\"\n",
    "    - Split the data into features (X) and target variable (y)\n",
    "    - OneHot-Encoding for categorical columns\n",
    "    - Split the data into training. validation and testing sets\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame train data\n",
    "        df_test (pd.DataFrame): DataFrame test data\n",
    "\n",
    "    Returns:\n",
    "        tuple: train_x, test_y, val_x, val_y, X_test, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "        # Define features (X) and target variable (y)\n",
    "    X_train = df_train.drop(columns=['user_of_latest_model'])  # Features\n",
    "    y_train = df_train['user_of_latest_model']  # Target variable\n",
    "    \n",
    "    X_test = df_test.drop(columns=['user_of_latest_model'])  # Features\n",
    "    y_test = df_test['user_of_latest_model']  # Target variable\n",
    "\n",
    "    # OneHot-Encoding for categorical columns\n",
    "    X_train = pd.get_dummies(X_train, columns=df_train.select_dtypes(include=['object']).columns.to_list(), drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=df_test.select_dtypes(include=['object']).columns.to_list(), drop_first=True)\n",
    "    \n",
    "    train_x, val_x, train_y, val_y = train_test_split(X_train, y_train, test_size=0.2, random_state=123)\n",
    "    \n",
    "    return train_x, val_x, train_y, val_y, X_test, y_test\n",
    "\n",
    "\n",
    "def train_test_model(df_train: pd.DataFrame,\n",
    "                        df_test: pd.DataFrame, \n",
    "                        model_name: str, \n",
    "                        models_func: str,\n",
    "                        n_opt_trials: int= 20) -> pd.DataFrame: \n",
    "    \"\"\"\n",
    "    - Adjust format of categorical columns\n",
    "    - train model on full training data\n",
    "    - Make predictions on the test data\n",
    "    - Evaluate the model using accuracy and F1-score\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame train data\n",
    "        df_test (pd.DataFrame): DataFrame test data\n",
    "        model_name (str): model name\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: df metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    train_x, val_x, train_y, val_y, X_test, y_test = split_train_test_data(df_train, df_test)\n",
    "           \n",
    "    # Train the model\n",
    "    model, study, val_f1_score, val_accuracy = models_func[model_name](train_x, val_x, train_y, val_y, n_opt_trials=n_opt_trials)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_accuracy = round(accuracy_score(y_test, y_pred),4)\n",
    "    test_f1_score = round(f1_score(y_test, y_pred),4)\n",
    "\n",
    "    # Store results in DataFrame\n",
    "    df_results = pd.DataFrame({'Model_Name': [model_name], \n",
    "                               'val_f1_score': [val_f1_score], \n",
    "                               'val_accuracy': [val_accuracy], \n",
    "                               'test_f1_score': [test_f1_score],\n",
    "                               'test_accuracy': [test_accuracy]})\n",
    "\n",
    "    return df_results, study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the dataframe to use them in the next step\n",
    "df_train = pd.read_csv(\"../../data/processed/task2_best_model_step3_train_data.csv\")\n",
    "df_test = pd.read_csv(\"../../data/processed/task2_best_model_step3_test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_func = {'RandomForest': train_random_forest, \n",
    "               'GradientBoosting': train_gradient_boosting, \n",
    "               'DecisionTree': train_deicision_tree,\n",
    "               'AdaBoost': train_adaboost, \n",
    "               'SVC': train_svc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score No Optimization: 0.7225806451612903\n",
      "Optimized Model F1 Score:  0.698\n",
      "No Optimization has better f1 score than optimized model\n"
     ]
    }
   ],
   "source": [
    "model_name = 'RandomForest'\n",
    "n_opt_trials = 20\n",
    "df_results_new, study = train_test_model(df_train=df_train, \n",
    "                                     df_test=df_test, \n",
    "                                     model_name=model_name, \n",
    "                                     models_func=models_func,\n",
    "                                     n_opt_trials=n_opt_trials)\n",
    "\n",
    "df_results = pd.concat([df_results, df_results_new], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model_Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "val_f1_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_f1_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8c369227-8420-477e-9f21-35027fbb6533",
       "rows": [
        [
         "0",
         "RandomForest",
         "0.7225806451612903",
         "0.7704",
         "0.7097",
         "0.766"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 1
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>0.7097</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model_Name  val_f1_score  val_accuracy  test_f1_score  test_accuracy\n",
       "0  RandomForest      0.722581        0.7704         0.7097          0.766"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score No Optimization: 0.6951219512195121\n",
      "Optimized Model F1 Score:  0.7152\n"
     ]
    }
   ],
   "source": [
    "model_name = 'GradientBoosting' \n",
    "n_opt_trials = 20\n",
    "df_results_new, study = train_test_model(df_train=df_train, \n",
    "                                     df_test=df_test, \n",
    "                                     model_name=model_name, \n",
    "                                     models_func=models_func,\n",
    "                                     n_opt_trials=n_opt_trials)\n",
    "df_results = pd.concat([df_results, df_results_new], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model_Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "val_f1_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_f1_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "87e5d412-d1b9-433a-a23c-4f26d7d9d853",
       "rows": [
        [
         "0",
         "RandomForest",
         "0.7225806451612903",
         "0.7704",
         "0.7097",
         "0.766"
        ],
        [
         "0",
         "GradientBoosting",
         "0.7152",
         "0.7602",
         "0.6856",
         "0.734"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>0.7097</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.715200</td>\n",
       "      <td>0.7602</td>\n",
       "      <td>0.6856</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model_Name  val_f1_score  val_accuracy  test_f1_score  test_accuracy\n",
       "0      RandomForest      0.722581        0.7704         0.7097          0.766\n",
       "0  GradientBoosting      0.715200        0.7602         0.6856          0.734"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score No Optimization: 0.6190476190476191\n",
      "Optimized Model F1 Score:  0.686\n"
     ]
    }
   ],
   "source": [
    "model_name = 'DecisionTree'\n",
    "n_opt_trials = 20\n",
    "df_results_new, study = train_test_model(df_train=df_train, \n",
    "                                     df_test=df_test, \n",
    "                                     model_name=model_name, \n",
    "                                     models_func=models_func,\n",
    "                                     n_opt_trials=n_opt_trials)\n",
    "df_results = pd.concat([df_results, df_results_new], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model_Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "val_f1_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_f1_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "519677db-0d7c-4e95-a1d1-ce1b27b3c61c",
       "rows": [
        [
         "0",
         "RandomForest",
         "0.7225806451612903",
         "0.7704",
         "0.7097",
         "0.766"
        ],
        [
         "0",
         "GradientBoosting",
         "0.7152",
         "0.7602",
         "0.6856",
         "0.734"
        ],
        [
         "0",
         "DecisionTree",
         "0.686",
         "0.7245",
         "0.6465",
         "0.696"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>0.7097</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.715200</td>\n",
       "      <td>0.7602</td>\n",
       "      <td>0.6856</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>0.6465</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model_Name  val_f1_score  val_accuracy  test_f1_score  test_accuracy\n",
       "0      RandomForest      0.722581        0.7704         0.7097          0.766\n",
       "0  GradientBoosting      0.715200        0.7602         0.6856          0.734\n",
       "0      DecisionTree      0.686000        0.7245         0.6465          0.696"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score No Optimization: 0.6666666666666666\n",
      "Optimized Model F1 Score:  0.671\n"
     ]
    }
   ],
   "source": [
    "model_name = 'AdaBoost'\n",
    "n_opt_trials = 20\n",
    "df_results_new, study = train_test_model(df_train=df_train, \n",
    "                                     df_test=df_test, \n",
    "                                     model_name=model_name, \n",
    "                                     models_func=models_func,\n",
    "                                     n_opt_trials=n_opt_trials)\n",
    "df_results = pd.concat([df_results, df_results_new], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Model_Name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "val_f1_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val_accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_f1_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "test_accuracy",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "46942d42-a80a-4ca6-abf9-ffb467cfda5c",
       "rows": [
        [
         "0",
         "RandomForest",
         "0.7225806451612903",
         "0.7704",
         "0.7097",
         "0.766"
        ],
        [
         "0",
         "GradientBoosting",
         "0.7152",
         "0.7602",
         "0.6856",
         "0.734"
        ],
        [
         "0",
         "DecisionTree",
         "0.686",
         "0.7245",
         "0.6465",
         "0.696"
        ],
        [
         "0",
         "AdaBoost",
         "0.671",
         "0.7398",
         "0.6717",
         "0.738"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>val_f1_score</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>0.7097</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoosting</td>\n",
       "      <td>0.715200</td>\n",
       "      <td>0.7602</td>\n",
       "      <td>0.6856</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.686000</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>0.6465</td>\n",
       "      <td>0.696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.671000</td>\n",
       "      <td>0.7398</td>\n",
       "      <td>0.6717</td>\n",
       "      <td>0.738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model_Name  val_f1_score  val_accuracy  test_f1_score  test_accuracy\n",
       "0      RandomForest      0.722581        0.7704         0.7097          0.766\n",
       "0  GradientBoosting      0.715200        0.7602         0.6856          0.734\n",
       "0      DecisionTree      0.686000        0.7245         0.6465          0.696\n",
       "0          AdaBoost      0.671000        0.7398         0.6717          0.738"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score No Optimization: 0.5\n"
     ]
    }
   ],
   "source": [
    "model_name = 'SVC'\n",
    "n_opt_trials = 20\n",
    "df_results_new, study = train_test_model(df_train=df_train, \n",
    "                                     df_test=df_test, \n",
    "                                     model_name=model_name, \n",
    "                                     models_func=models_func,\n",
    "                                     n_opt_trials=n_opt_trials)\n",
    "df_results = pd.concat([df_results, df_results_new], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
